# SmolLM SFT (Supervised Fine-Tuning) Configuration

# Base model (set via --base-model CLI arg)
model:
  base_checkpoint: null

# Tokenizer (same as pretraining)
tokenizer:
  name: "meta-llama/Llama-2-7b-hf"

# SFT Dataset
data:
  dataset: "HuggingFaceTB/smoltalk"
  split: "train"
  max_samples: null  # null = use all

# Training configuration
training:
  epochs: 2
  micro_batch_size: 16
  gradient_accumulation: 4
  seq_len: 2048
  precision: "bf16"

# Optimizer (just AdamW for fine-tuning, no Muon)
optimizer:
  lr: 0.00002
  weight_decay: 0.01
  grad_clip: 1.0
  betas: [0.9, 0.95]

# Scheduler
scheduler:
  warmup_ratio: 0.03
  scheduler_type: "cosine"
  min_lr_ratio: 0.1

# Validation
validation:
  eval_every_steps: 50
  eval_samples: 500

# Logging
logging:
  log_every_steps: 10
  project: "smol-lm"
  use_wandb: true

# Checkpointing
checkpoint:
  save_every_steps: 200
  checkpoint_dir: "/content/drive/MyDrive/smol-lm-checkpoints/sft"
  keep_last_n: 2
